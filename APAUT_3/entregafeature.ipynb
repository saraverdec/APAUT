{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a127746",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "Enrique Juliá Arévalo, Sara Verde Camacho, Leo Pérez Peña"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb36921",
   "metadata": {},
   "source": [
    "Se comienza cargando los paquetes necesarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4f4b84e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d432adff",
   "metadata": {},
   "source": [
    "**In this practical, you will become familiarized with some basic feature selection methods implemented in scikit-learn. Consider the prostate dataset that is attached to this practical. You are asked to:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722a052b",
   "metadata": {},
   "source": [
    "Se carga el dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "25ba0541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100_g_at</th>\n",
       "      <th>1000_at</th>\n",
       "      <th>1001_at</th>\n",
       "      <th>1002_f_at</th>\n",
       "      <th>1003_s_at</th>\n",
       "      <th>1004_at</th>\n",
       "      <th>1005_at</th>\n",
       "      <th>1006_at</th>\n",
       "      <th>1007_s_at</th>\n",
       "      <th>1008_f_at</th>\n",
       "      <th>...</th>\n",
       "      <th>AFFX-ThrX-5_at</th>\n",
       "      <th>AFFX-ThrX-M_at</th>\n",
       "      <th>AFFX-TrpnX-3_at</th>\n",
       "      <th>AFFX-TrpnX-5_at</th>\n",
       "      <th>AFFX-TrpnX-M_at</th>\n",
       "      <th>AFFX-YEL002c/WBP1_at</th>\n",
       "      <th>AFFX-YEL018w/_at</th>\n",
       "      <th>AFFX-YEL021w/URA3_at</th>\n",
       "      <th>AFFX-YEL024w/RIP1_at</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.927460</td>\n",
       "      <td>7.391657</td>\n",
       "      <td>3.812922</td>\n",
       "      <td>3.453385</td>\n",
       "      <td>6.070151</td>\n",
       "      <td>5.527153</td>\n",
       "      <td>5.812353</td>\n",
       "      <td>3.167275</td>\n",
       "      <td>7.354981</td>\n",
       "      <td>9.419909</td>\n",
       "      <td>...</td>\n",
       "      <td>3.770583</td>\n",
       "      <td>2.884436</td>\n",
       "      <td>2.730025</td>\n",
       "      <td>3.126168</td>\n",
       "      <td>2.870161</td>\n",
       "      <td>3.082210</td>\n",
       "      <td>2.747289</td>\n",
       "      <td>3.226588</td>\n",
       "      <td>3.480196</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.222432</td>\n",
       "      <td>7.329050</td>\n",
       "      <td>3.958028</td>\n",
       "      <td>3.407226</td>\n",
       "      <td>5.921265</td>\n",
       "      <td>5.376464</td>\n",
       "      <td>7.303408</td>\n",
       "      <td>3.108708</td>\n",
       "      <td>7.391872</td>\n",
       "      <td>10.539579</td>\n",
       "      <td>...</td>\n",
       "      <td>3.190759</td>\n",
       "      <td>2.460119</td>\n",
       "      <td>2.696578</td>\n",
       "      <td>2.675271</td>\n",
       "      <td>2.940032</td>\n",
       "      <td>3.126269</td>\n",
       "      <td>3.013745</td>\n",
       "      <td>3.517859</td>\n",
       "      <td>3.428752</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.776402</td>\n",
       "      <td>7.664007</td>\n",
       "      <td>3.783702</td>\n",
       "      <td>3.152019</td>\n",
       "      <td>5.452293</td>\n",
       "      <td>5.111794</td>\n",
       "      <td>7.207638</td>\n",
       "      <td>3.077360</td>\n",
       "      <td>7.488371</td>\n",
       "      <td>6.833428</td>\n",
       "      <td>...</td>\n",
       "      <td>3.325183</td>\n",
       "      <td>2.603014</td>\n",
       "      <td>2.469759</td>\n",
       "      <td>2.615746</td>\n",
       "      <td>2.510172</td>\n",
       "      <td>2.730814</td>\n",
       "      <td>2.613696</td>\n",
       "      <td>2.823436</td>\n",
       "      <td>3.049716</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.919134</td>\n",
       "      <td>7.469634</td>\n",
       "      <td>4.004581</td>\n",
       "      <td>3.341170</td>\n",
       "      <td>6.070925</td>\n",
       "      <td>5.296108</td>\n",
       "      <td>8.744059</td>\n",
       "      <td>3.117104</td>\n",
       "      <td>7.203028</td>\n",
       "      <td>10.400557</td>\n",
       "      <td>...</td>\n",
       "      <td>3.625057</td>\n",
       "      <td>2.765521</td>\n",
       "      <td>2.681757</td>\n",
       "      <td>3.310741</td>\n",
       "      <td>3.197177</td>\n",
       "      <td>3.414182</td>\n",
       "      <td>3.193867</td>\n",
       "      <td>3.353537</td>\n",
       "      <td>3.567482</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.113561</td>\n",
       "      <td>7.322408</td>\n",
       "      <td>4.242724</td>\n",
       "      <td>3.489324</td>\n",
       "      <td>6.141657</td>\n",
       "      <td>5.628390</td>\n",
       "      <td>6.825370</td>\n",
       "      <td>3.794904</td>\n",
       "      <td>7.403024</td>\n",
       "      <td>10.240322</td>\n",
       "      <td>...</td>\n",
       "      <td>3.698067</td>\n",
       "      <td>3.026876</td>\n",
       "      <td>2.691670</td>\n",
       "      <td>3.236030</td>\n",
       "      <td>3.003906</td>\n",
       "      <td>3.081497</td>\n",
       "      <td>2.963307</td>\n",
       "      <td>3.472050</td>\n",
       "      <td>3.598103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 12626 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   100_g_at   1000_at   1001_at  1002_f_at  1003_s_at   1004_at   1005_at  \\\n",
       "0  6.927460  7.391657  3.812922   3.453385   6.070151  5.527153  5.812353   \n",
       "1  7.222432  7.329050  3.958028   3.407226   5.921265  5.376464  7.303408   \n",
       "2  6.776402  7.664007  3.783702   3.152019   5.452293  5.111794  7.207638   \n",
       "3  6.919134  7.469634  4.004581   3.341170   6.070925  5.296108  8.744059   \n",
       "4  7.113561  7.322408  4.242724   3.489324   6.141657  5.628390  6.825370   \n",
       "\n",
       "    1006_at  1007_s_at  1008_f_at  ...  AFFX-ThrX-5_at  AFFX-ThrX-M_at  \\\n",
       "0  3.167275   7.354981   9.419909  ...        3.770583        2.884436   \n",
       "1  3.108708   7.391872  10.539579  ...        3.190759        2.460119   \n",
       "2  3.077360   7.488371   6.833428  ...        3.325183        2.603014   \n",
       "3  3.117104   7.203028  10.400557  ...        3.625057        2.765521   \n",
       "4  3.794904   7.403024  10.240322  ...        3.698067        3.026876   \n",
       "\n",
       "   AFFX-TrpnX-3_at  AFFX-TrpnX-5_at  AFFX-TrpnX-M_at  AFFX-YEL002c/WBP1_at  \\\n",
       "0         2.730025         3.126168         2.870161              3.082210   \n",
       "1         2.696578         2.675271         2.940032              3.126269   \n",
       "2         2.469759         2.615746         2.510172              2.730814   \n",
       "3         2.681757         3.310741         3.197177              3.414182   \n",
       "4         2.691670         3.236030         3.003906              3.081497   \n",
       "\n",
       "   AFFX-YEL018w/_at  AFFX-YEL021w/URA3_at  AFFX-YEL024w/RIP1_at  Y  \n",
       "0          2.747289              3.226588              3.480196  0  \n",
       "1          3.013745              3.517859              3.428752  1  \n",
       "2          2.613696              2.823436              3.049716  0  \n",
       "3          3.193867              3.353537              3.567482  0  \n",
       "4          2.963307              3.472050              3.598103  1  \n",
       "\n",
       "[5 rows x 12626 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('prostate.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840747d8",
   "metadata": {},
   "source": [
    "1. Estimate the performance of the nearest neighbor classifier on this dataset using 10-times 10-fold cross validation when all the features are used for prediction. The number of neighbors should be chosen using an inner cross-validation procedure. You can use 5-fold cross validation for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "723b3d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data.iloc[:, :-1]).astype(float)\n",
    "y = np.array(data.iloc[:, -1]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9e128043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7936363636363637 ± 0.14013275877768422\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'knn__n_neighbors': np.arange(1, 21)}\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', preprocessing.StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "# Validación cruzada anidada\n",
    "# - Outer loop: 10 repeticiones de 10-fold CV\n",
    "# - Inner loop: 5-fold CV para ajustar k\n",
    "\n",
    "out_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "in_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "clf = GridSearchCV(pipe, param_grid=param_grid, cv=in_cv)\n",
    "\n",
    "\n",
    "nested_scores = cross_val_score(clf, X, y, cv=out_cv)\n",
    "\n",
    "print(f\"Accuracy: {nested_scores.mean()} ± {nested_scores.std()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48992bf",
   "metadata": {},
   "source": [
    "Versión más larga:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8668582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1, K: 7, accuracy = 0.7272727272727273\n",
      "Iteration: 2, K: 6, accuracy = 0.8181818181818182\n",
      "Iteration: 3, K: 7, accuracy = 0.7\n",
      "Iteration: 4, K: 3, accuracy = 0.9\n",
      "Iteration: 5, K: 7, accuracy = 0.8\n",
      "Iteration: 6, K: 7, accuracy = 0.7\n",
      "Iteration: 7, K: 8, accuracy = 1.0\n",
      "Iteration: 8, K: 7, accuracy = 0.7\n",
      "Iteration: 9, K: 3, accuracy = 0.9\n",
      "Iteration: 10, K: 8, accuracy = 0.7\n"
     ]
    }
   ],
   "source": [
    "k_values = np.arange(3, 10) # menor rango porque tarda mucho\n",
    "out_scores = []\n",
    "score_per_k = {}\n",
    "\n",
    "for out_i, (train_val_index, test_index) in enumerate(out_cv.split(X, y)):\n",
    "    X_train_val, X_test = X[train_val_index], X[test_index]\n",
    "    y_train_val, y_test = y[train_val_index], y[test_index]\n",
    "\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train_val)\n",
    "    X_train_scaled = scaler.transform(X_train_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    in_cv = StratifiedKFold(n_splits=5) \n",
    "\n",
    "    mean_in_score = []\n",
    "\n",
    "    for k in k_values:\n",
    "        in_score = []\n",
    "\n",
    "        for train_index, val_index in in_cv.split(X_train_val, y_train_val):\n",
    "            X_train, X_val = X_train_val[train_index], X_train_val[val_index]\n",
    "            y_train, y_val = y_train_val[train_index], y_train_val[val_index]\n",
    "\n",
    "            scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "            in_X_train_scaled = scaler.transform(X_train)\n",
    "            in_X_test_scaled = scaler.transform(X_val)\n",
    "            \n",
    "            knn = KNeighborsClassifier(n_neighbors=k)\n",
    "            knn.fit(in_X_train_scaled, y_train)\n",
    "            acc = accuracy_score(y_val, knn.predict(in_X_test_scaled))\n",
    "            in_score.append(acc)\n",
    "        \n",
    "        mean_in_score.append(np.mean(in_score))\n",
    "    \n",
    "    final_k = k_values[np.argmax(mean_in_score)]\n",
    "    final_knn =KNeighborsClassifier(n_neighbors= final_k)\n",
    "    final_knn.fit(X_train_scaled, y_train_val)\n",
    "    acc = accuracy_score(y_test, final_knn.predict(X_test_scaled))\n",
    "    out_scores.append(acc)\n",
    "    print(f\"Iteration: {out_i + 1}, K: {final_k}, accuracy = {acc}\")\n",
    "    \n",
    "    if final_k not in score_per_k:\n",
    "        score_per_k[final_k] = [acc]\n",
    "    else:\n",
    "        score_per_k[final_k].append(acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "adb922b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.7945454545454547\n"
     ]
    }
   ],
   "source": [
    "out_scores = np.array(out_scores)\n",
    "print(f\"Mean accuracy: {out_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "141ae52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy for 7 neighbors: 0.7254545454545456\n",
      "Average accuracy for 6 neighbors: 0.8181818181818182\n",
      "Average accuracy for 3 neighbors: 0.9\n",
      "Average accuracy for 8 neighbors: 0.85\n"
     ]
    }
   ],
   "source": [
    "for k in score_per_k:\n",
    "    print(f\"Average accuracy for {k} neighbors: {np.array(score_per_k[k]).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b381ca",
   "metadata": {},
   "source": [
    "2. Estimate the performance of the nearest neighbor classifier on the same dataset when using a feature selection technique based on the F-score (ANOVA) that picks up the 10 most relevant features. Use the same cross-validation methods as in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4fe2449b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9209090909090909 ± 0.09783186791718376\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('scaler', preprocessing.StandardScaler()),\n",
    "    ('feature_selection', SelectKBest(score_func=f_classif, k=10)),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "param_grid = {'knn__n_neighbors': np.arange(1, 21)}\n",
    "\n",
    "outer_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "clf = GridSearchCV(pipe, param_grid=param_grid, cv=inner_cv)\n",
    "\n",
    "nested_scores = cross_val_score(clf, X, y, cv=outer_cv)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {nested_scores.mean()} ± {nested_scores.std()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decd6c91",
   "metadata": {},
   "source": [
    "3. Repeat the previous experiment but when a random forest is used to pick up the 10 most relevant features. Use an initial filtering method based on the F-score to keep only the 20% most promising features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3031f65",
   "metadata": {},
   "source": [
    "4. What feature selection method performs best? Can you explain why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a6342b",
   "metadata": {},
   "source": [
    "**Now we will address the problem of analyzing the trade-off between interpretability and prediction accuracy. For this, you are asked to:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f72f722",
   "metadata": {},
   "source": [
    "1. Estimate the performance of the nearest neighbor classifier with K=3 as a function of the features used for prediction. Use a 10-times 10-fold cross-validation method and plot the results obtained. That is prediction error vs. the number of features used for prediction. Use the F-score for feature selection. Report results from 1 feature to 200 features. Not all features need to be explored. Use a higher resolution when you are closer to 1 feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4a45da",
   "metadata": {},
   "source": [
    "2. Repeat that process when the feature selection is done externally to the cross-validation loop using all the available data. Include these results in the previous plot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee7f100",
   "metadata": {},
   "source": [
    "3. Are the two estimates obtained similar? What are their differences? If they are different try to explain why this is the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee82b26",
   "metadata": {},
   "source": [
    "4. By taking a look at these results, what is the optimal number of features to use in this dataset in terms of interpretability vs. prediction error?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92700c17",
   "metadata": {},
   "source": [
    "5. Given the results obtained in this part of the practical, you are asked to indicate which particular features should be used for prediction on this dataset. Include a list with them. Take a look at the documentation of SelectKBest from scikit-learn to understand how to do this. Use all available data to provide such a list of features. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
