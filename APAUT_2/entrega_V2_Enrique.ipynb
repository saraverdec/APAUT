{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Clasification Systems\n",
    "Enrique Juliá Arévalo, Sara Verde Camacho, Leo Pérez Peña"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this exercise, you are asked to compare the prediction error of:\n",
    "\n",
    "- The Naive Bayes Classifier\n",
    "- LDA\n",
    "- QDA\n",
    "- Nearest Shrunken Centroids Classifier\n",
    "\n",
    "On the Breast Cancer dataset provided in the previous notebooks, and the Prostate cancer dataset attached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importantly:\n",
    "\n",
    "- Use a random split of 2 / 3 of the data for training and 1 / 3 for testing each classifier. \n",
    "- Any hyper-parameter of each method should be tuned using a grid-search guided by an inner cross-validation procedure that uses only training data. If test data is used to tune the hyper-parameters (even indirectly) the submission will be penalized.\n",
    "- To reduce the variance of the estimates, report average error results over 20 different partitions of the data into training and testing as described above. You can use a for loop over the steps described above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Give some comments about the results and respond to these questions based on what you have seen in the lectures:\n",
    "\n",
    "- What method performs best on each dataset in terms of prediction error?\n",
    "- What method is more flexible according to what we have seen in the lectures? Is this compatible with the obtained results?\n",
    "- What method is more robust to over-fitting according to what we have seen in the lectures? Is this compatible with the obtained results?\n",
    "- Discuss and compare, regarding the bias and the variance, the procedure used to estimate the generalization error of a classifier trained on the available data with 10-fold-cross validation and leave-one-out cross-validation. Which one has a bigger bias and a bigger variance? Explain your response. You need not carry out additional experiments, only explain what you should expect to obtain according to what you have seen in the lectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos los módulos necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abrimos y analizamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_data = pd.read_csv('wdbc.csv', header=None)\n",
    "prostate_data = pd. read_csv('prostate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1      2      3       4       5        6        7       8   \\\n",
       "0    842302  M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001   \n",
       "1    842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n",
       "2  84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n",
       "3  84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   \n",
       "4  84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n",
       "\n",
       "        9   ...     22     23      24      25      26      27      28      29  \\\n",
       "0  0.14710  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1  0.07017  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.12790  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.10520  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.10430  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "       30       31  \n",
       "0  0.4601  0.11890  \n",
       "1  0.2750  0.08902  \n",
       "2  0.3613  0.08758  \n",
       "3  0.6638  0.17300  \n",
       "4  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_breast = breast_data.values[:, 2:].astype(float)\n",
    "y_breast = breast_data.values[:, 1] == 'M'\n",
    "y_breast = y_breast.astype(int) # 1 when M and 0 when B\n",
    "breast_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   100_g_at   1000_at   1001_at  1002_f_at  1003_s_at   1004_at   1005_at  \\\n",
      "0  6.927460  7.391657  3.812922   3.453385   6.070151  5.527153  5.812353   \n",
      "1  7.222432  7.329050  3.958028   3.407226   5.921265  5.376464  7.303408   \n",
      "2  6.776402  7.664007  3.783702   3.152019   5.452293  5.111794  7.207638   \n",
      "3  6.919134  7.469634  4.004581   3.341170   6.070925  5.296108  8.744059   \n",
      "4  7.113561  7.322408  4.242724   3.489324   6.141657  5.628390  6.825370   \n",
      "\n",
      "    1006_at  1007_s_at  1008_f_at  ...  AFFX-ThrX-5_at  AFFX-ThrX-M_at  \\\n",
      "0  3.167275   7.354981   9.419909  ...        3.770583        2.884436   \n",
      "1  3.108708   7.391872  10.539579  ...        3.190759        2.460119   \n",
      "2  3.077360   7.488371   6.833428  ...        3.325183        2.603014   \n",
      "3  3.117104   7.203028  10.400557  ...        3.625057        2.765521   \n",
      "4  3.794904   7.403024  10.240322  ...        3.698067        3.026876   \n",
      "\n",
      "   AFFX-TrpnX-3_at  AFFX-TrpnX-5_at  AFFX-TrpnX-M_at  AFFX-YEL002c/WBP1_at  \\\n",
      "0         2.730025         3.126168         2.870161              3.082210   \n",
      "1         2.696578         2.675271         2.940032              3.126269   \n",
      "2         2.469759         2.615746         2.510172              2.730814   \n",
      "3         2.681757         3.310741         3.197177              3.414182   \n",
      "4         2.691670         3.236030         3.003906              3.081497   \n",
      "\n",
      "   AFFX-YEL018w/_at  AFFX-YEL021w/URA3_at  AFFX-YEL024w/RIP1_at  Y  \n",
      "0          2.747289              3.226588              3.480196  0  \n",
      "1          3.013745              3.517859              3.428752  1  \n",
      "2          2.613696              2.823436              3.049716  0  \n",
      "3          3.193867              3.353537              3.567482  0  \n",
      "4          2.963307              3.472050              3.598103  1  \n",
      "\n",
      "[5 rows x 12626 columns]\n",
      "52.0\n"
     ]
    }
   ],
   "source": [
    "print(prostate_data.head())\n",
    "print(prostate_data.values[:, -1].sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prostate = prostate_data.values[:,:-1].astype(float)\n",
    "y_prostate = prostate_data.values[:,-1] == 1 # 1 when Malignant and 0 when Benign\n",
    "y_prostate = y_prostate.astype(int) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partición de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a separar los datos en aquellos que utilizaremos para entrenar los modelos y para testarlos. Como se indica en el enunciado, emplearemos 1/3 para el test (0.33), y 2/3 para el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition 1 done\n",
      "Partition 2 done\n",
      "Partition 3 done\n",
      "Partition 4 done\n",
      "Partition 5 done\n",
      "Partition 6 done\n",
      "Partition 7 done\n",
      "Partition 8 done\n",
      "Partition 9 done\n",
      "Partition 10 done\n",
      "Partition 11 done\n",
      "Partition 12 done\n",
      "Partition 13 done\n",
      "Partition 14 done\n",
      "Partition 15 done\n",
      "Partition 16 done\n",
      "Partition 17 done\n",
      "Partition 18 done\n",
      "Partition 19 done\n",
      "Partition 20 done\n"
     ]
    }
   ],
   "source": [
    "breast_complete = []\n",
    "prostate_complete = []\n",
    "\n",
    "for i in range(20):\n",
    "    bre_X_train, bre_X_test, bre_y_train, bre_y_test = train_test_split( \\\n",
    "        X_breast, y_breast, test_size= 0.33, random_state=i)\n",
    "    breast_complete.append([bre_X_train, bre_X_test, bre_y_train, bre_y_test])\n",
    "\n",
    "    pro_X_train, pro_X_test, pro_y_train, pro_y_test = train_test_split(\\\n",
    "        X_prostate, y_prostate, test_size= 0.33, random_state=i)\n",
    "    prostate_complete.append([pro_X_train, pro_X_test, pro_y_train, pro_y_test])\n",
    "    print(f'Partition {i+1} done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalización de los datos\n",
    "\n",
    "Para realizar la normalización hemos ajustado los datos train y posteriormente hemos utilizado los parámetros obtenidos para transformar tanto los dataset de train como los de test. De esta forma podemos saber si los parámetros que se generan se ajustan bien a datos desconocidos (de los cuales no tenemos por qué conocer la media ni la desviación estándar). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# breast dataset\n",
    "for i in breast_complete:\n",
    "    bre_X_train, bre_X_test, bre_y_train, bre_y_test=i\n",
    "    scaler = preprocessing.StandardScaler().fit(bre_X_train)\n",
    "    bre_X_train_scaled = scaler.transform(bre_X_train)\n",
    "    bre_X_test_scaled = scaler.transform(bre_X_test)\n",
    "    i.append(bre_X_train_scaled)\n",
    "    i.append(bre_X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prostate dataset\n",
    "for i in prostate_complete:\n",
    "    pro_X_train, pro_X_test, pro_y_train, pro_y_test=i\n",
    "    scaler = preprocessing.StandardScaler().fit(pro_X_train)\n",
    "    pro_X_train_scaled = scaler.transform(pro_X_train)\n",
    "    pro_X_test_scaled = scaler.transform(pro_X_test)\n",
    "    i.append(pro_X_train_scaled)\n",
    "    i.append(pro_X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador de Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition done. Prediction accuracy: 0.898936170212766\n",
      "Partition done. Prediction accuracy: 0.9361702127659575\n",
      "Partition done. Prediction accuracy: 0.9308510638297872\n",
      "Partition done. Prediction accuracy: 0.9521276595744681\n",
      "Partition done. Prediction accuracy: 0.9361702127659575\n",
      "Partition done. Prediction accuracy: 0.9308510638297872\n",
      "Partition done. Prediction accuracy: 0.9521276595744681\n",
      "Partition done. Prediction accuracy: 0.9468085106382979\n",
      "Partition done. Prediction accuracy: 0.9308510638297872\n",
      "Partition done. Prediction accuracy: 0.9361702127659575\n",
      "Partition done. Prediction accuracy: 0.9361702127659575\n",
      "Partition done. Prediction accuracy: 0.9414893617021277\n",
      "Partition done. Prediction accuracy: 0.9202127659574468\n",
      "Partition done. Prediction accuracy: 0.9148936170212766\n",
      "Partition done. Prediction accuracy: 0.9521276595744681\n",
      "Partition done. Prediction accuracy: 0.9308510638297872\n",
      "Partition done. Prediction accuracy: 0.9414893617021277\n",
      "Partition done. Prediction accuracy: 0.9468085106382979\n",
      "Partition done. Prediction accuracy: 0.9095744680851063\n",
      "Partition done. Prediction accuracy: 0.925531914893617\n",
      "Prediction accuracy\n",
      "MEAN: 0.9335106382978726, SD: 0.014022793964323486\n"
     ]
    }
   ],
   "source": [
    "pred_accuracy=[]\n",
    "for i in breast_complete:\n",
    "    bre_X_train, bre_X_test, bre_y_train, bre_y_test, bre_X_train_scaled, bre_X_test_scaled=i\n",
    "    nb.fit(bre_X_train_scaled, bre_y_train)\n",
    "    bre_y_pred = nb.predict(bre_X_test_scaled)\n",
    "    conf = confusion_matrix(bre_y_test, bre_y_pred)\n",
    "    TN = conf[0][0]\n",
    "    TP = conf[1][1]\n",
    "    FP = conf[0][1]\n",
    "    FN = conf[1][0]\n",
    "    pred_accuracy.append(((TP + TN) / (TN + TP + FP + FN)))\n",
    "    print(f'Partition done. Prediction accuracy: {((TP + TN) / (TN + TP + FP + FN))}')\n",
    "\n",
    "pred_accuracy = np.array(pred_accuracy)\n",
    "print(F\"Prediction accuracy\\nMEAN: {pred_accuracy.mean()}, SD: {pred_accuracy.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition done. Prediction accuracy: 0.6764705882352942\n",
      "Partition done. Prediction accuracy: 0.8235294117647058\n",
      "Partition done. Prediction accuracy: 0.4411764705882353\n",
      "Partition done. Prediction accuracy: 0.7352941176470589\n",
      "Partition done. Prediction accuracy: 0.7058823529411765\n",
      "Partition done. Prediction accuracy: 0.7647058823529411\n",
      "Partition done. Prediction accuracy: 0.5882352941176471\n",
      "Partition done. Prediction accuracy: 0.7058823529411765\n",
      "Partition done. Prediction accuracy: 0.7647058823529411\n",
      "Partition done. Prediction accuracy: 0.5\n",
      "Partition done. Prediction accuracy: 0.5588235294117647\n",
      "Partition done. Prediction accuracy: 0.4411764705882353\n",
      "Partition done. Prediction accuracy: 0.6470588235294118\n",
      "Partition done. Prediction accuracy: 0.7352941176470589\n",
      "Partition done. Prediction accuracy: 0.5588235294117647\n",
      "Partition done. Prediction accuracy: 0.5\n",
      "Partition done. Prediction accuracy: 0.5294117647058824\n",
      "Partition done. Prediction accuracy: 0.8529411764705882\n",
      "Partition done. Prediction accuracy: 0.6176470588235294\n",
      "Partition done. Prediction accuracy: 0.7647058823529411\n",
      "Prediction accuracy\n",
      "MEAN: 0.6455882352941178, SD: 0.12250097097277782\n"
     ]
    }
   ],
   "source": [
    "pred_accuracy=[]\n",
    "for i in prostate_complete:\n",
    "    pro_X_train, pro_X_test, pro_y_train, pro_y_test, pro_X_train_scaled, pro_X_test_scaled=i\n",
    "    nb.fit(pro_X_train_scaled, pro_y_train)\n",
    "    pro_y_pred = nb.predict(pro_X_test_scaled)\n",
    "    conf = confusion_matrix(pro_y_test, pro_y_pred)\n",
    "    TN = conf[0][0]\n",
    "    TP = conf[1][1]\n",
    "    FP = conf[0][1]\n",
    "    FN = conf[1][0]\n",
    "    pred_accuracy.append(((TP + TN) / (TN + TP + FP + FN)))\n",
    "    print(f'Partition done. Prediction accuracy: {((TP + TN) / (TN + TP + FP + FN))}')\n",
    "\n",
    "pred_accuracy = np.array(pred_accuracy)\n",
    "print(F\"Prediction accuracy\\nMEAN: {pred_accuracy.mean()}, SD: {pred_accuracy.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib as mpl\n",
    "from matplotlib import colors\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, make_scorer, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition done. Prediction accuracy: 0.973404255319149\n",
      "Partition done. Prediction accuracy: 0.9627659574468085\n",
      "Partition done. Prediction accuracy: 0.9521276595744681\n",
      "Partition done. Prediction accuracy: 0.9627659574468085\n",
      "Partition done. Prediction accuracy: 0.9787234042553191\n",
      "Partition done. Prediction accuracy: 0.9627659574468085\n",
      "Partition done. Prediction accuracy: 0.9468085106382979\n",
      "Partition done. Prediction accuracy: 0.9627659574468085\n",
      "Partition done. Prediction accuracy: 0.9680851063829787\n",
      "Partition done. Prediction accuracy: 0.9680851063829787\n",
      "Partition done. Prediction accuracy: 0.9627659574468085\n",
      "Partition done. Prediction accuracy: 0.9521276595744681\n",
      "Partition done. Prediction accuracy: 0.9574468085106383\n",
      "Partition done. Prediction accuracy: 0.9627659574468085\n",
      "Partition done. Prediction accuracy: 0.9521276595744681\n",
      "Partition done. Prediction accuracy: 0.9521276595744681\n",
      "Partition done. Prediction accuracy: 0.9574468085106383\n",
      "Partition done. Prediction accuracy: 0.9574468085106383\n",
      "Partition done. Prediction accuracy: 0.9680851063829787\n",
      "Partition done. Prediction accuracy: 0.9308510638297872\n",
      "Prediction accuracy\n",
      "MEAN: 0.9595744680851064, SD: 0.010148289376776018\n"
     ]
    }
   ],
   "source": [
    "pred_accuracy=[]\n",
    "for i in breast_complete:\n",
    "    bre_X_train, bre_X_test, bre_y_train, bre_y_test, bre_X_train_scaled, bre_X_test_scaled=i\n",
    "    lda.fit(bre_X_train_scaled, bre_y_train)\n",
    "    bre_y_pred = lda.predict(bre_X_test_scaled)\n",
    "    conf = confusion_matrix(bre_y_test, bre_y_pred)\n",
    "    TN = conf[0][0]\n",
    "    TP = conf[1][1]\n",
    "    FP = conf[0][1]\n",
    "    FN = conf[1][0]\n",
    "    pred_accuracy.append(((TP + TN) / (TN + TP + FP + FN)))\n",
    "    print(f'Partition done. Prediction accuracy: {((TP + TN) / (TN + TP + FP + FN))}')\n",
    "\n",
    "pred_accuracy = np.array(pred_accuracy)\n",
    "print(F\"Prediction accuracy\\nMEAN: {pred_accuracy.mean()}, SD: {pred_accuracy.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition done. Prediction accuracy: 0.9117647058823529\n",
      "Partition done. Prediction accuracy: 0.8529411764705882\n",
      "Partition done. Prediction accuracy: 0.7941176470588235\n",
      "Partition done. Prediction accuracy: 0.8823529411764706\n",
      "Partition done. Prediction accuracy: 0.8529411764705882\n",
      "Partition done. Prediction accuracy: 0.8529411764705882\n",
      "Partition done. Prediction accuracy: 0.8529411764705882\n",
      "Partition done. Prediction accuracy: 0.8235294117647058\n",
      "Partition done. Prediction accuracy: 0.8235294117647058\n",
      "Partition done. Prediction accuracy: 0.9117647058823529\n",
      "Partition done. Prediction accuracy: 0.7941176470588235\n",
      "Partition done. Prediction accuracy: 0.8529411764705882\n",
      "Partition done. Prediction accuracy: 0.8823529411764706\n",
      "Partition done. Prediction accuracy: 0.8529411764705882\n",
      "Partition done. Prediction accuracy: 0.9117647058823529\n",
      "Partition done. Prediction accuracy: 0.7647058823529411\n",
      "Partition done. Prediction accuracy: 0.7941176470588235\n",
      "Partition done. Prediction accuracy: 0.8235294117647058\n",
      "Partition done. Prediction accuracy: 0.8529411764705882\n",
      "Partition done. Prediction accuracy: 0.8235294117647058\n",
      "Prediction accuracy\n",
      "MEAN: 0.8455882352941178, SD: 0.04040774018833555\n"
     ]
    }
   ],
   "source": [
    "pred_accuracy=[]\n",
    "for i in prostate_complete:\n",
    "    pro_X_train, pro_X_test, pro_y_train, pro_y_test, pro_X_train_scaled, pro_X_test_scaled=i\n",
    "    lda.fit(pro_X_train_scaled, pro_y_train)\n",
    "    pro_y_pred = lda.predict(pro_X_test_scaled)\n",
    "    conf = confusion_matrix(pro_y_test, pro_y_pred)\n",
    "    TN = conf[0][0]\n",
    "    TP = conf[1][1]\n",
    "    FP = conf[0][1]\n",
    "    FN = conf[1][0]\n",
    "    pred_accuracy.append(((TP + TN) / (TN + TP + FP + FN)))\n",
    "    print(f'Partition done. Prediction accuracy: {((TP + TN) / (TN + TP + FP + FN))}')\n",
    "\n",
    "pred_accuracy = np.array(pred_accuracy)\n",
    "print(F\"Prediction accuracy\\nMEAN: {pred_accuracy.mean()}, SD: {pred_accuracy.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([ ('qda', QuadraticDiscriminantAnalysis()) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_param_values = np.linspace(0, 1, 21).tolist()\n",
    "param_grid = { 'qda__reg_param': reg_param_values }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition done. Prediction accuracy: 0.9574468085106383\n",
      "Partition done. Prediction accuracy: 0.9787234042553191\n",
      "Partition done. Prediction accuracy: 0.9680851063829787\n",
      "Partition done. Prediction accuracy: 0.973404255319149\n",
      "Partition done. Prediction accuracy: 0.973404255319149\n",
      "Partition done. Prediction accuracy: 0.9680851063829787\n",
      "Partition done. Prediction accuracy: 0.9680851063829787\n",
      "Partition done. Prediction accuracy: 0.9680851063829787\n",
      "Partition done. Prediction accuracy: 0.9627659574468085\n",
      "Partition done. Prediction accuracy: 0.973404255319149\n",
      "Partition done. Prediction accuracy: 0.9840425531914894\n",
      "Partition done. Prediction accuracy: 0.9574468085106383\n",
      "Partition done. Prediction accuracy: 0.9414893617021277\n",
      "Partition done. Prediction accuracy: 0.9840425531914894\n",
      "Partition done. Prediction accuracy: 0.973404255319149\n",
      "Partition done. Prediction accuracy: 0.973404255319149\n",
      "Partition done. Prediction accuracy: 0.973404255319149\n",
      "Partition done. Prediction accuracy: 0.9574468085106383\n",
      "Partition done. Prediction accuracy: 0.9521276595744681\n",
      "Partition done. Prediction accuracy: 0.9521276595744681\n",
      "Prediction accuracy\n",
      "MEAN: 0.9670212765957448, SD: 0.01084897768849528\n"
     ]
    }
   ],
   "source": [
    "pred_accuracy = []\n",
    "\n",
    "for i in breast_complete:\n",
    "    \n",
    "    bre_X_train, bre_X_test, bre_y_train, bre_y_test, bre_X_train_scaled, bre_X_test_scaled = i\n",
    "\n",
    "    #We do the cross-validation\n",
    "    skfold = RepeatedStratifiedKFold(n_splits=10, n_repeats=1, random_state=0)\n",
    "    gridcv = GridSearchCV(pipeline, cv=skfold, n_jobs=1, param_grid=param_grid, \\\n",
    "        scoring = make_scorer(accuracy_score))\n",
    "    result = gridcv.fit(bre_X_train_scaled, bre_y_train)\n",
    "\n",
    "    #We exctract the value of the parameter with the biggest test score\n",
    "    accuracies = gridcv.cv_results_['mean_test_score']\n",
    "    best_reg_param_value = reg_param_values[max(enumerate(accuracies), key=lambda x: x[1])[0]]\n",
    "    \n",
    "    qda = QuadraticDiscriminantAnalysis(reg_param = best_reg_param_value)\n",
    "\n",
    "    qda.fit(bre_X_train_scaled, bre_y_train)  \n",
    "    bre_y_pred = qda.predict(bre_X_test_scaled)\n",
    "    \n",
    "    conf = confusion_matrix(bre_y_test, bre_y_pred)\n",
    "    TN = conf[0][0]\n",
    "    TP = conf[1][1]\n",
    "    FP = conf[0][1]\n",
    "    FN = conf[1][0]\n",
    "    pred_accuracy.append(((TP + TN) / (TN + TP + FP + FN)))\n",
    "    print(f'Partition done. Prediction accuracy: {((TP + TN) / (TN + TP + FP + FN))}')\n",
    "\n",
    "pred_accuracy = np.array(pred_accuracy)\n",
    "print(f\"Prediction accuracy\\nMEAN: {pred_accuracy.mean()}, SD: {pred_accuracy.std()}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition done. Prediction accuracy: 0.6176470588235294\n",
      "Partition done. Prediction accuracy: 0.6764705882352942\n",
      "Partition done. Prediction accuracy: 0.4411764705882353\n",
      "Partition done. Prediction accuracy: 0.6764705882352942\n",
      "Partition done. Prediction accuracy: 0.8235294117647058\n",
      "Partition done. Prediction accuracy: 0.6176470588235294\n",
      "Partition done. Prediction accuracy: 0.7647058823529411\n",
      "Partition done. Prediction accuracy: 0.7941176470588235\n",
      "Partition done. Prediction accuracy: 0.7941176470588235\n",
      "Partition done. Prediction accuracy: 0.5882352941176471\n",
      "Partition done. Prediction accuracy: 0.6470588235294118\n",
      "Partition done. Prediction accuracy: 0.6764705882352942\n",
      "Partition done. Prediction accuracy: 0.7058823529411765\n",
      "Partition done. Prediction accuracy: 0.7352941176470589\n",
      "Partition done. Prediction accuracy: 0.8823529411764706\n",
      "Partition done. Prediction accuracy: 0.5882352941176471\n",
      "Partition done. Prediction accuracy: 0.7352941176470589\n",
      "Partition done. Prediction accuracy: 0.8235294117647058\n",
      "Partition done. Prediction accuracy: 0.7941176470588235\n",
      "Partition done. Prediction accuracy: 0.7352941176470589\n",
      "Prediction accuracy\n",
      "MEAN: 0.7058823529411766, SD: 0.10188534162169864\n"
     ]
    }
   ],
   "source": [
    "pred_accuracy = []\n",
    "\n",
    "for i in prostate_complete:\n",
    "    \n",
    "    pro_X_train, pro_X_test, pro_y_train, pro_y_test, pro_X_train_scaled, pro_X_test_scaled = i\n",
    "    \n",
    "    #We do the cross-validation\n",
    "    skfold = RepeatedStratifiedKFold(n_splits=10, n_repeats=1, random_state=0)\n",
    "    gridcv = GridSearchCV(pipeline, cv=skfold, n_jobs=1, param_grid=param_grid, \\\n",
    "        scoring = make_scorer(accuracy_score))\n",
    "    result = gridcv.fit(pro_X_train_scaled, pro_y_train)\n",
    "    \n",
    "    #We exctract the value of the parameter with the biggest test score\n",
    "    accuracies = gridcv.cv_results_['mean_test_score']\n",
    "    best_reg_param_value = reg_param_values[max(enumerate(accuracies), key=lambda x: x[1])[0]]\n",
    "\n",
    "    qda = QuadraticDiscriminantAnalysis(reg_param = best_reg_param_value)\n",
    "\n",
    "    qda.fit(pro_X_train_scaled, pro_y_train)\n",
    "    pro_y_pred = qda.predict(pro_X_test_scaled)\n",
    "    \n",
    "    conf = confusion_matrix(pro_y_test, pro_y_pred)\n",
    "    TN = conf[0][0]\n",
    "    TP = conf[1][1]\n",
    "    FP = conf[0][1]\n",
    "    FN = conf[1][0]\n",
    "    pred_accuracy.append(((TP + TN) / (TN + TP + FP + FN)))\n",
    "    print(f'Partition done. Prediction accuracy: {((TP + TN) / (TN + TP + FP + FN))}')\n",
    "\n",
    "pred_accuracy = np.array(pred_accuracy)\n",
    "print(F\"Prediction accuracy\\nMEAN: {pred_accuracy.mean()}, SD: {pred_accuracy.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador de Nearest Shrunken Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, make_scorer, confusion_matrix\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([ ('nsc', NearestCentroid()) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "shrinkage_param_values = np.linspace(1e-6, 8, 21).tolist()\n",
    "param_grid_nsc = {'nsc__shrink_threshold': shrinkage_param_values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition done. Prediction accuracy: 0.9148936170212766\n",
      "Partition done. Prediction accuracy: 0.925531914893617\n",
      "Partition done. Prediction accuracy: 0.9148936170212766\n",
      "Partition done. Prediction accuracy: 0.9414893617021277\n",
      "Partition done. Prediction accuracy: 0.9202127659574468\n",
      "Partition done. Prediction accuracy: 0.9574468085106383\n",
      "Partition done. Prediction accuracy: 0.9414893617021277\n",
      "Partition done. Prediction accuracy: 0.9468085106382979\n",
      "Partition done. Prediction accuracy: 0.925531914893617\n",
      "Partition done. Prediction accuracy: 0.9414893617021277\n",
      "Partition done. Prediction accuracy: 0.9521276595744681\n",
      "Partition done. Prediction accuracy: 0.9468085106382979\n",
      "Partition done. Prediction accuracy: 0.9202127659574468\n",
      "Partition done. Prediction accuracy: 0.9414893617021277\n",
      "Partition done. Prediction accuracy: 0.9414893617021277\n",
      "Partition done. Prediction accuracy: 0.925531914893617\n",
      "Partition done. Prediction accuracy: 0.9361702127659575\n",
      "Partition done. Prediction accuracy: 0.9414893617021277\n",
      "Partition done. Prediction accuracy: 0.9308510638297872\n",
      "Partition done. Prediction accuracy: 0.9202127659574468\n",
      "Prediction accuracy\n",
      "MEAN: 0.9343085106382981, SD: 0.012392018890661445\n"
     ]
    }
   ],
   "source": [
    "pred_accuracy = []\n",
    "\n",
    "for i in breast_complete:\n",
    "    \n",
    "    bre_X_train, bre_X_test, bre_y_train, bre_y_test, bre_X_train_scaled, bre_X_test_scaled = i\n",
    "\n",
    "    #We do the cross-validation\n",
    "    gridcv_nsc = GridSearchCV(pipeline, cv=skfold, n_jobs=1, param_grid=param_grid_nsc, \\\n",
    "        scoring=make_scorer(accuracy_score))\n",
    "    result_nsc = gridcv_nsc.fit(bre_X_train_scaled, bre_y_train)\n",
    "\n",
    "    #We exctract the value of the parameter with the biggest test score\n",
    "    accuracies = gridcv_nsc.cv_results_['mean_test_score']\n",
    "    \n",
    "    nsc = NearestCentroid(shrink_threshold = shrinkage_param_values[np.argmax(accuracies)])\n",
    "\n",
    "    nsc.fit(bre_X_train_scaled, bre_y_train)\n",
    "    bre_y_pred = nsc.predict(bre_X_test_scaled)\n",
    "    \n",
    "    conf = confusion_matrix(bre_y_test, bre_y_pred)\n",
    "    TN = conf[0][0]\n",
    "    TP = conf[1][1]\n",
    "    FP = conf[0][1]\n",
    "    FN = conf[1][0]\n",
    "    pred_accuracy.append(((TP + TN) / (TN + TP + FP + FN)))\n",
    "    print(f'Partition done. Prediction accuracy: {((TP + TN) / (TN + TP + FP + FN))}')\n",
    "\n",
    "pred_accuracy = np.array(pred_accuracy)\n",
    "print(f\"Prediction accuracy\\nMEAN: {pred_accuracy.mean()}, SD: {pred_accuracy.std()}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition done. Prediction accuracy: 0.9117647058823529\n",
      "Partition done. Prediction accuracy: 0.9411764705882353\n",
      "Partition done. Prediction accuracy: 0.9117647058823529\n",
      "Partition done. Prediction accuracy: 0.9117647058823529\n",
      "Partition done. Prediction accuracy: 0.9411764705882353\n",
      "Partition done. Prediction accuracy: 0.9411764705882353\n",
      "Partition done. Prediction accuracy: 0.9117647058823529\n",
      "Partition done. Prediction accuracy: 0.8529411764705882\n",
      "Partition done. Prediction accuracy: 0.9117647058823529\n",
      "Partition done. Prediction accuracy: 0.8823529411764706\n",
      "Partition done. Prediction accuracy: 0.7941176470588235\n",
      "Partition done. Prediction accuracy: 0.7647058823529411\n",
      "Partition done. Prediction accuracy: 0.8529411764705882\n",
      "Partition done. Prediction accuracy: 0.8529411764705882\n",
      "Partition done. Prediction accuracy: 0.8235294117647058\n",
      "Partition done. Prediction accuracy: 0.8235294117647058\n",
      "Partition done. Prediction accuracy: 0.8529411764705882\n",
      "Partition done. Prediction accuracy: 0.9411764705882353\n",
      "Partition done. Prediction accuracy: 0.9411764705882353\n",
      "Partition done. Prediction accuracy: 0.9117647058823529\n",
      "Prediction accuracy\n",
      "MEAN: 0.8838235294117647, SD: 0.052179985291794635\n"
     ]
    }
   ],
   "source": [
    "pred_accuracy = []\n",
    "\n",
    "for i in prostate_complete:\n",
    "    \n",
    "    pro_X_train, pro_X_test, pro_y_train, pro_y_test, pro_X_train_scaled, pro_X_test_scaled = i\n",
    "\n",
    "    #We do the cross-validation\n",
    "    gridcv_nsc = GridSearchCV(pipeline, cv=skfold, n_jobs=1, param_grid=param_grid_nsc, \\\n",
    "        scoring=make_scorer(accuracy_score))\n",
    "    result_nsc = gridcv_nsc.fit(pro_X_train_scaled, pro_y_train)\n",
    "\n",
    "    #We exctract the value of the parameter with the biggest test score\n",
    "    accuracies = gridcv_nsc.cv_results_['mean_test_score']\n",
    "    \n",
    "    nsc = NearestCentroid(shrink_threshold = shrinkage_param_values[ np.argmax(accuracies)])\n",
    "\n",
    "    nsc.fit(pro_X_train_scaled, pro_y_train)\n",
    "    pro_y_pred = nsc.predict(pro_X_test_scaled)\n",
    "    \n",
    "    conf = confusion_matrix(pro_y_test, pro_y_pred)\n",
    "    TN = conf[0][0]\n",
    "    TP = conf[1][1]\n",
    "    FP = conf[0][1]\n",
    "    FN = conf[1][0]\n",
    "    pred_accuracy.append(((TP + TN) / (TN + TP + FP + FN)))\n",
    "    print(f'Partition done. Prediction accuracy: {((TP + TN) / (TN + TP + FP + FN))}')\n",
    "\n",
    "pred_accuracy = np.array(pred_accuracy)\n",
    "print(f\"Prediction accuracy\\nMEAN: {pred_accuracy.mean()}, SD: {pred_accuracy.std()}\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
