{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Clasification Systems\n",
    "Enrique Juliá Arévalo, Sara Verde Camacho, Leo Pérez Peña"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_data = pd.read_csv('wdbc.csv', header=None)\n",
    "prostate_data = pd. read_csv('prostate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1      2      3       4       5        6        7       8   \\\n",
       "0    842302  M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001   \n",
       "1    842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n",
       "2  84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n",
       "3  84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   \n",
       "4  84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n",
       "\n",
       "        9   ...     22     23      24      25      26      27      28      29  \\\n",
       "0  0.14710  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1  0.07017  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.12790  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.10520  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.10430  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "       30       31  \n",
       "0  0.4601  0.11890  \n",
       "1  0.2750  0.08902  \n",
       "2  0.3613  0.08758  \n",
       "3  0.6638  0.17300  \n",
       "4  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_breast = breast_data.values[:, 2:].astype(float)\n",
    "y_breast = breast_data.values[:, 1] == 'B'\n",
    "y_breast = y_breast.astype(int) # 0 when M and 1 when B\n",
    "breast_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   100_g_at   1000_at   1001_at  1002_f_at  1003_s_at   1004_at   1005_at  \\\n",
      "0  6.927460  7.391657  3.812922   3.453385   6.070151  5.527153  5.812353   \n",
      "1  7.222432  7.329050  3.958028   3.407226   5.921265  5.376464  7.303408   \n",
      "2  6.776402  7.664007  3.783702   3.152019   5.452293  5.111794  7.207638   \n",
      "3  6.919134  7.469634  4.004581   3.341170   6.070925  5.296108  8.744059   \n",
      "4  7.113561  7.322408  4.242724   3.489324   6.141657  5.628390  6.825370   \n",
      "\n",
      "    1006_at  1007_s_at  1008_f_at  ...  AFFX-ThrX-5_at  AFFX-ThrX-M_at  \\\n",
      "0  3.167275   7.354981   9.419909  ...        3.770583        2.884436   \n",
      "1  3.108708   7.391872  10.539579  ...        3.190759        2.460119   \n",
      "2  3.077360   7.488371   6.833428  ...        3.325183        2.603014   \n",
      "3  3.117104   7.203028  10.400557  ...        3.625057        2.765521   \n",
      "4  3.794904   7.403024  10.240322  ...        3.698067        3.026876   \n",
      "\n",
      "   AFFX-TrpnX-3_at  AFFX-TrpnX-5_at  AFFX-TrpnX-M_at  AFFX-YEL002c/WBP1_at  \\\n",
      "0         2.730025         3.126168         2.870161              3.082210   \n",
      "1         2.696578         2.675271         2.940032              3.126269   \n",
      "2         2.469759         2.615746         2.510172              2.730814   \n",
      "3         2.681757         3.310741         3.197177              3.414182   \n",
      "4         2.691670         3.236030         3.003906              3.081497   \n",
      "\n",
      "   AFFX-YEL018w/_at  AFFX-YEL021w/URA3_at  AFFX-YEL024w/RIP1_at  Y  \n",
      "0          2.747289              3.226588              3.480196  0  \n",
      "1          3.013745              3.517859              3.428752  1  \n",
      "2          2.613696              2.823436              3.049716  0  \n",
      "3          3.193867              3.353537              3.567482  0  \n",
      "4          2.963307              3.472050              3.598103  1  \n",
      "\n",
      "[5 rows x 12626 columns]\n",
      "52.0\n"
     ]
    }
   ],
   "source": [
    "print(prostate_data.head())\n",
    "print(prostate_data.values[:, -1].sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prostate = prostate_data.values[:,:-1].astype(float)\n",
    "y_prostate = prostate_data.values[:,-1] == 0 # para tenerlo igual que el otro\n",
    "                                             # 0 = tumor, 1 = tejido sano\n",
    "y_prostate = y_prostate.astype(int) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partición de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a separar los datos en aquellos que utilizaremos para entrenar los modelos y para testarlos. Como se indica en el enunciado, emplearemos 1/3 para el test (0.33), y 2/3 para el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_complete = []\n",
    "for i in range(20):\n",
    "    bre_X_train, bre_X_test, bre_y_train, bre_y_test = train_test_split( \\\n",
    "        X_breast, y_breast, test_size= 0.33)\n",
    "    breast_complete.append([bre_X_train, bre_X_test, bre_y_train, bre_y_test])\n",
    "    \n",
    "prostate_complete = []\n",
    "for i in range(20):\n",
    "    pro_X_train, pro_X_test, pro_y_train, pro_y_test = train_test_split(\\\n",
    "        X_prostate, y_prostate, test_size= 0.33)\n",
    "    prostate_complete.append([pro_X_train, pro_X_test, pro_y_train, pro_y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización de los datos\n",
    "\n",
    "Para realizar la normalización hemos ajustado los datos train y posteriormente hemos utilizado los parámetros obtenidos para transformar tanto los dataset de train como los de test. De esta forma podemos saber si los parámetros que se generan se ajustan bien a datos desconocidos (de los cuales no tenemos por qué conocer la media ni la desviación estándar). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# breast dataset\n",
    "for i in breast_complete:\n",
    "    bre_X_train, bre_X_test, bre_y_train, bre_y_test=i\n",
    "    scaler = preprocessing.StandardScaler().fit(bre_X_train)\n",
    "    bre_X_train_scaled = scaler.transform(bre_X_train)\n",
    "    bre_X_test_scaled = scaler.transform(bre_X_test)\n",
    "    i.append(bre_X_train_scaled)\n",
    "    i.append(bre_X_test_scaled)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prostate dataset\n",
    "for i in prostate_complete:\n",
    "    pro_X_train, pro_X_test, pro_y_train, pro_y_test=i\n",
    "    scaler = preprocessing.StandardScaler().fit(pro_X_train)\n",
    "    pro_X_train_scaled = scaler.transform(pro_X_train)\n",
    "    pro_X_test_scaled = scaler.transform(pro_X_test)\n",
    "    i.append(pro_X_train_scaled)\n",
    "    i.append(pro_X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador de Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy\n",
      "MEAN: 0.9281914893617023, SD: 0.01134613245090508\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "pred_accuracy=[]\n",
    "for i in breast_complete:\n",
    "    bre_X_train, bre_X_test, bre_y_train, bre_y_test, bre_X_train_scaled, bre_X_test_scaled=i\n",
    "    nb.fit(bre_X_train_scaled, bre_y_train)\n",
    "    bre_y_pred = nb.predict(bre_X_test_scaled)\n",
    "    conf = confusion_matrix(bre_y_test, bre_y_pred)\n",
    "    TN = conf[0][0]\n",
    "    TP = conf[1][1]\n",
    "    FP = conf[0][1]\n",
    "    FN = conf[1][0]\n",
    "    pred_accuracy.append(((TP + TN) / (TN + TP + FP + FN)))\n",
    "\n",
    "pred_accuracy = np.array(pred_accuracy)\n",
    "print(F\"Prediction accuracy\\nMEAN: {pred_accuracy.mean()}, SD: {pred_accuracy.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy\n",
      "MEAN: 0.6279411764705881, SD: 0.06724625508925691\n"
     ]
    }
   ],
   "source": [
    "pred_accuracy=[]\n",
    "for i in prostate_complete:\n",
    "    pro_X_train, pro_X_test, pro_y_train, pro_y_test, pro_X_train_scaled, pro_X_test_scaled=i\n",
    "    nb.fit(pro_X_train_scaled, pro_y_train)\n",
    "    pro_y_pred = nb.predict(pro_X_test_scaled)\n",
    "    conf = confusion_matrix(pro_y_test, pro_y_pred)\n",
    "    TN = conf[0][0]\n",
    "    TP = conf[1][1]\n",
    "    FP = conf[0][1]\n",
    "    FN = conf[1][0]\n",
    "    pred_accuracy.append(((TP + TN) / (TN + TP + FP + FN)))\n",
    "\n",
    "pred_accuracy = np.array(pred_accuracy)\n",
    "print(F\"Prediction accuracy\\nMEAN: {pred_accuracy.mean()}, SD: {pred_accuracy.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib as mpl\n",
    "from matplotlib import colors\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, make_scorer, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy\n",
      "MEAN: 0.9555851063829788, SD: 0.016927517703159117\n"
     ]
    }
   ],
   "source": [
    "pred_accuracy=[]\n",
    "for i in breast_complete:\n",
    "    bre_X_train, bre_X_test, bre_y_train, bre_y_test, bre_X_train_scaled, bre_X_test_scaled=i\n",
    "    lda.fit(bre_X_train_scaled, bre_y_train)\n",
    "    bre_y_pred = lda.predict(bre_X_test_scaled)\n",
    "    conf = confusion_matrix(bre_y_test, bre_y_pred)\n",
    "    TN = conf[0][0]\n",
    "    TP = conf[1][1]\n",
    "    FP = conf[0][1]\n",
    "    FN = conf[1][0]\n",
    "    pred_accuracy.append(((TP + TN) / (TN + TP + FP + FN)))\n",
    "\n",
    "pred_accuracy = np.array(pred_accuracy)\n",
    "print(F\"Prediction accuracy\\nMEAN: {pred_accuracy.mean()}, SD: {pred_accuracy.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy\n",
      "MEAN: 0.8455882352941178, SD: 0.056479012851975055\n"
     ]
    }
   ],
   "source": [
    "pred_accuracy=[]\n",
    "for i in prostate_complete:\n",
    "    pro_X_train, pro_X_test, pro_y_train, pro_y_test, pro_X_train_scaled, pro_X_test_scaled=i\n",
    "    lda.fit(pro_X_train_scaled, pro_y_train)\n",
    "    pro_y_pred = lda.predict(pro_X_test_scaled)\n",
    "    conf = confusion_matrix(pro_y_test, pro_y_pred)\n",
    "    TN = conf[0][0]\n",
    "    TP = conf[1][1]\n",
    "    FP = conf[0][1]\n",
    "    FN = conf[1][0]\n",
    "    pred_accuracy.append(((TP + TN) / (TN + TP + FP + FN)))\n",
    "\n",
    "pred_accuracy = np.array(pred_accuracy)\n",
    "print(F\"Prediction accuracy\\nMEAN: {pred_accuracy.mean()}, SD: {pred_accuracy.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda = QuadraticDiscriminantAnalysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy\n",
      "MEAN: 0.949468085106383, SD: 0.01340383315782358\n"
     ]
    }
   ],
   "source": [
    "pred_accuracy = []\n",
    "\n",
    "for i in breast_complete:\n",
    "    bre_X_train, bre_X_test, bre_y_train, bre_y_test, bre_X_train_scaled, bre_X_test_scaled = i\n",
    "    qda.fit(bre_X_train_scaled, bre_y_train)  \n",
    "    bre_y_pred = qda.predict(bre_X_test_scaled)\n",
    "    \n",
    "    conf = confusion_matrix(bre_y_test, bre_y_pred)\n",
    "    TN = conf[0][0]\n",
    "    TP = conf[1][1]\n",
    "    FP = conf[0][1]\n",
    "    FN = conf[1][0]\n",
    "    pred_accuracy.append(((TP + TN) / (TN + TP + FP + FN)))\n",
    "\n",
    "pred_accuracy = np.array(pred_accuracy)\n",
    "print(f\"Prediction accuracy\\nMEAN: {pred_accuracy.mean()}, SD: {pred_accuracy.std()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy\n",
      "MEAN: 0.49558823529411755, SD: 0.08688924262777913\n"
     ]
    }
   ],
   "source": [
    "pred_accuracy=[]\n",
    "for i in prostate_complete:\n",
    "    pro_X_train, pro_X_test, pro_y_train, pro_y_test, pro_X_train_scaled, pro_X_test_scaled=i\n",
    "    qda.fit(pro_X_train_scaled, pro_y_train)\n",
    "    pro_y_pred = qda.predict(pro_X_test_scaled)\n",
    "    \n",
    "    conf = confusion_matrix(pro_y_test, pro_y_pred)\n",
    "    TN = conf[0][0]\n",
    "    TP = conf[1][1]\n",
    "    FP = conf[0][1]\n",
    "    FN = conf[1][0]\n",
    "    pred_accuracy.append(((TP + TN) / (TN + TP + FP + FN)))\n",
    "\n",
    "pred_accuracy = np.array(pred_accuracy)\n",
    "print(F\"Prediction accuracy\\nMEAN: {pred_accuracy.mean()}, SD: {pred_accuracy.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificador de Nearest Shrunken Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, make_scorer, confusion_matrix\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsc = NearestCentroid(shrink_threshold=0.5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de predicción\n",
      "MEDIA: 0.9276595744680852, DESVÍO: 0.013393274800015101\n"
     ]
    }
   ],
   "source": [
    "pred_accuracy = []\n",
    "\n",
    "\n",
    "for i in breast_complete:\n",
    "    bre_X_train, bre_X_test, bre_y_train, bre_y_test, bre_X_train_scaled, bre_X_test_scaled = i\n",
    "    nsc.fit(bre_X_train_scaled, bre_y_train)  \n",
    "    bre_y_pred = nsc.predict(bre_X_test_scaled)\n",
    "    \n",
    "    conf = confusion_matrix(bre_y_test, bre_y_pred)\n",
    "    TN = conf[0][0]\n",
    "    TP = conf[1][1]\n",
    "    FP = conf[0][1]\n",
    "    FN = conf[1][0]\n",
    "    pred_accuracy.append(((TP + TN) / (TN + TP + FP + FN)))\n",
    "\n",
    "\n",
    "pred_accuracy = np.array(pred_accuracy)\n",
    "print(f\"Precisión de predicción\\nMEAN: {pred_accuracy.mean()}, SD: {pred_accuracy.std()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de predicción\n",
      "MEAN: 0.6426470588235293, SD: 0.08228726372669283\n"
     ]
    }
   ],
   "source": [
    "pred_accuracy = []\n",
    "\n",
    "\n",
    "for i in prostate_complete:\n",
    "    pro_X_train, pro_X_test, pro_y_train, pro_y_test, pro_X_train_scaled, pro_X_test_scaled = i\n",
    "    nsc.fit(pro_X_train_scaled, pro_y_train)  \n",
    "    pro_y_pred = nsc.predict(pro_X_test_scaled)\n",
    "    \n",
    "    conf = confusion_matrix(pro_y_test, pro_y_pred)\n",
    "    TN = conf[0][0]\n",
    "    TP = conf[1][1]\n",
    "    FP = conf[0][1]\n",
    "    FN = conf[1][0]\n",
    "    pred_accuracy.append(((TP + TN) / (TN + TP + FP + FN)))\n",
    "\n",
    "\n",
    "pred_accuracy = np.array(pred_accuracy)\n",
    "print(f\"Precisión de predicción\\nMEAN: {pred_accuracy.mean()}, SD: {pred_accuracy.std()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
